{
    "MODEL_ID": "meta-llama/Meta-Llama-3.1-8B-Instruct",
    "DATASET_NAME": "gretelai/synthetic_text_to_sql",
    "OUTPUT_DIR_BASE": "/mnt/pvc/finetuned_llama3_1_8b_gretel_sql",
    "USE_QLORA": true,
    "LORA_ALPHA": 16,
    "LORA_DROPOUT": 0.1,
    "LORA_R": 64,
    "BNB_4BIT_COMPUTE_DTYPE": "bfloat16",
    "BNB_4BIT_QUANT_TYPE": "nf4",
    "USE_NESTED_QUANT": false,
    "NUM_TRAIN_EPOCHS": 1,
    "PER_DEVICE_TRAIN_BATCH_SIZE": 2,
    "GRADIENT_ACCUMULATION_STEPS": 4,
    "LEARNING_RATE": 2e-4,
    "WEIGHT_DECAY": 0.001,
    "OPTIM": "paged_adamw_32bit",
    "LR_SCHEDULER_TYPE": "cosine",
    "MAX_GRAD_NORM": 0.3,
    "WARMUP_RATIO": 0.03,
    "LOGGING_STEPS": 10,
    "SAVE_STRATEGY": "steps",
    "SAVE_STEPS_SFT": 50,
    "EVALUATION_STRATEGY_SFT": "steps",
    "EVAL_STEPS_SFT": 50,
    "REPORT_TO": "tensorboard",
    "MAX_SEQ_LENGTH": 1024,
    "PACKING": false,
    "GROUP_BY_LENGTH": true,
    "LLAMA_TARGET_MODULES": [
        "q_proj", "k_proj", "v_proj", "o_proj",
        "gate_proj", "up_proj", "down_proj"
    ],
    "NUM_EVAL_SAMPLES_INFERENCE": 2,
    "MAX_NEW_GENERATION_TOKENS_INFERENCE": 300,
    "SFT_SUBDIR_NAME": "sft_model_output_sql_gretel",
    "MERGED_MODEL_SUBDIR_NAME": "final_merged_model_on_gcs",
    "FULL_FT_MODEL_SUBDIR_NAME": "final_model_on_gcs",
    "INFERENCE": false
}